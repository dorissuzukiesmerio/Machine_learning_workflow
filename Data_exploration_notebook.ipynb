{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_exploration_notebook.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOSuYVDoBCGjP4q2DJ/kn6u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dorissuzukiesmerio/Machine_learning_workflow/blob/main/Data_exploration_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DATA EXPLORATION NOTEBOOK**"
      ],
      "metadata": {
        "id": "ZKYFlWSzNiWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "NOTE: If the dataset is too large, use a sample of the original dataset. Use the stratified sampling using pyspark's sampleBy method to ensure that the distribution of the target column is retained\n",
        "\n",
        "https://spark.apache.org/docs/latest/api/python/reference/api/pyspark.sql.DataFrameStatFunctions.sampleBy.html"
      ],
      "metadata": {
        "id": "SrsWnqyWHWdI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import uuid\n",
        "import shutil\n",
        "import pandas as pd\n",
        "import databricks.automl_runtime\n",
        "\n",
        "from mlflow.tracking import MlflowClient\n",
        "\n",
        "# Download input data from mlflow into a pandas DataFrame\n",
        "# create temp directory to download data\n",
        "temp_dir = os.path.join(os.environ[\"SPARK_LOCAL_DIRS\"], \"tmp\", str(uuid.uuid4())[:8])\n",
        "os.makedirs(temp_dir)\n",
        "\n",
        "# download the artifact and read it\n",
        "client = MlflowClient()\n",
        "training_data_path = client.download_artifacts(\"801f5b02d78841189752ac71f921cadf\", \"data\", temp_dir)\n",
        "df = pd.read_parquet(os.path.join(training_data_path, \"training_data\"))\n",
        "\n",
        "# delete the temp data\n",
        "shutil.rmtree(temp_dir)\n",
        "\n",
        "target_col = \"is_reader\"\n",
        "\n",
        "# Convert columns detected to be of semantic type categorical\n",
        "categorical_columns = [\"male\", \"bk_textbook\", \"bk_religiousbook\", \"bk_magazine\", \"bk_newspaper\", \"bk_storybook\", \"bk_coloringbook\", \"bk_comicbook\", \"bk_healthpassport\", \"bk_none_book\", \"bk_no_answer_book\", \"helped_athome\", \"family_read\", \"told_story\", \"teacher_read\", \"teacher_question_read\", \"read_classmate\", \"read_quietly_alone\", \"learned_songs_or_games_school\", \"teacher_sounds_letters_words\", \"attend_readingcamp\", \"lastweek_attended_readingcamp\"]\n",
        "df[categorical_columns] = df[categorical_columns].applymap(str)"
      ],
      "metadata": {
        "id": "ewjYVAZQHzZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Semantic Type Detection Alerts\n",
        "For details about the definition of the semantic types and how to override the detection, see Databricks documentation on semantic type detection.\n",
        "\n",
        "Semantic type categorical detected for columns attend_readingcamp, bk_coloringbook, bk_comicbook, bk_healthpassport, bk_magazine, bk_newspaper, bk_no_answer_book, bk_none_book, bk_religiousbook, bk_storybook, bk_textbook, family_read, helped_athome, lastweek_attended_readingcamp, learned_songs_or_games_school, male, read_classmate, read_quietly_alone, teacher_question_read, teacher_read, teacher_sounds_letters_words, told_story. Training notebooks will encode features based on categorical transformations."
      ],
      "metadata": {
        "id": "teHVrQ9JM8ya"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Profiling Results"
      ],
      "metadata": {
        "id": "BKr7ViAXM_i9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas_profiling import ProfileReport\n",
        "df_profile = ProfileReport(df, minimal=True, title=\"Profiling Report\", progress_bar=False, infer_dtypes=False)\n",
        "profile_html = df_profile.to_html()\n",
        "\n",
        "displayHTML(profile_html)"
      ],
      "metadata": {
        "id": "JVPp-zOyNBtg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}